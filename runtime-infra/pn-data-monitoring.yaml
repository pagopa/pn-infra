AWSTemplateFormatVersion: 2010-09-09
Description: 'This template deploys the resources for the data monitoring'

Parameters:  
  ConfinfoDynamoDbExportBucketName:
    Type: String
    Default: ''
    Description: Name of the confinfo bucket created for the data monitoring (leave blank in Confinfo account)

  PnCoreAwsAccountId:
    Type: String
    Description: Core Account ID (leave blank in Core account)
    Default: ''

  ParquetBucketPath:
    Type: String
    Description: parquet files s3 bucket path
    Default: 'parquet'

  ReportsBucketPath:
    Type: String
    Description: reports files bucket path
    Default: 'reports'

  LogsBucketName:
    Type: String
    Description: Name of the logs bucket

  LogsBucketKmsKeyArn:
    Type: String
    Description: Name of the logs bucket KMS key ARN

  DataMonitoringIndexCronExpression:
    Type: String
    Description: Cron expression for the scheduled rule, e.g. cron(0 9 * * ? *)
    Default: 'cron(30 6 * * ? *)'

  #Dynamodb export parameters:

  DynamoDbExportTableNames:
    Type: String
    Default: ""
    Description: DynamoDB List of Table to export

  DynamoDbExportPrefix:
    Type: String
    Description: String Prefix after S3Prefix
    Default: incremental2024

  EnvironmentType:
    Type: String
    Description: Environment type (e.g. dev, test, prod)

  DataMonitoringScriptVersion:
    Type: String
    Description: Version of the bi_or_not_bi__ec_metadata scripts
    Default: ec_metadata_extract_v0_2

  DataMonitoringPrototypeVersion:
    Type: String
    Description: Version of the pn-prototype scripts
    Default: main

  DataLakeAccountId:
    Type: String
    Description: Datalake AWS Account ID
    Default: ''
  
  DataLakeRoleName:
    Type: String
    Description: Datalake Role Name
    Default: 'pagopa-pn'
  
  DataMonitoringSlackEmailTo:
    Type: String
    Description: Slack Email channel
    Default: ''

  PaperRequestErrorDumpFuctionCronExpression:
    Type: String
    Description: Cron expression for the scheduled rule, e.g. cron(0 9 * * ? *)
    Default: ''

  PaperRequestErrorDumpFuctionDelete:
    Type: String
    Description: Condition for remove item form PaperRequestError DynamoDb table
    Default: 'false'

  PresignedUrlTimeOfexpiration:
    Type: Number
    Description: Presigned URL Time of Expiration
    Default: 259200 

  TemplateBucketBaseUrl:
    Type: String
    Description: URL to load infrastructure model fragments from

  AlarmSNSTopicArn:
    Type: String

Conditions:
  IsConfinfoAccount: !Not [ !Equals [!Ref PnCoreAwsAccountId, '' ] ]
  IsCoreAccount: !Equals [!Ref PnCoreAwsAccountId, '' ]
  IsDatalakeAccount: !Not [ !Equals [!Ref DataLakeAccountId, '' ] ]
  IsDatalakeAccountInCore: !And [ !Condition IsDatalakeAccount, !Condition IsCoreAccount ]
  HasCronExpression: !Not [ !Equals [!Ref DataMonitoringIndexCronExpression, '' ] ]
  HasDynamoDbExportTableNames: !Not [ !Equals [!Ref DynamoDbExportTableNames, '' ] ]
  HasCronExpressionLambdaPaperError: !Not [ !Equals [!Ref PaperRequestErrorDumpFuctionCronExpression, '' ] ]

Resources:
  
  # s3 bucket with name BucketName
  DataMonitoringBucket:
    Type: AWS::S3::Bucket
    DeletionPolicy: Retain
    UpdateReplacePolicy: Retain
    Properties:
      BucketName: !Sub pn-datamonitoring-${AWS::Region}-${AWS::AccountId}
          
  DataMonitoringBucketPolicy:
    Condition: IsConfinfoAccount
    Type: AWS::S3::BucketPolicy
    Properties:
      Bucket: !Ref DataMonitoringBucket
      PolicyDocument:
        Version: "2012-10-17"
        Statement:
          - Effect: Allow
            Action:
              - "s3:Get*"
              - "s3:List*"              
            Resource: 
              - !Sub "arn:aws:s3:::${DataMonitoringBucket}"
              - !Sub "arn:aws:s3:::${DataMonitoringBucket}/*"   
            Principal:
              AWS: 
                - !Sub "arn:${AWS::Partition}:iam::${PnCoreAwsAccountId}:root"
            Condition:
              ArnLike:
                aws:PrincipalArn: 
                  - !Sub "arn:${AWS::Partition}:iam::${PnCoreAwsAccountId}:role/pn-data-monitoring-codebuild-role"
                  - !Sub "arn:${AWS::Partition}:iam::${PnCoreAwsAccountId}:role/pn-data-monitoring-ec2-service-role"
                  - !Sub "arn:${AWS::Partition}:iam::${PnCoreAwsAccountId}:instance-profile/pn-data-monitoring-ec2-instance-profile"
                  - !Sub "arn:${AWS::Partition}:sts::${PnCoreAwsAccountId}:assumed-role/pn-data-monitoring-ec2-service-role/*"
          - Effect: Allow
            Action:
              - "s3:PutObject"
            Resource: 
              - !Sub "arn:aws:s3:::${DataMonitoringBucket}/${ParquetBucketPath}/*"
            Principal:
              AWS: 
                - !Sub "arn:${AWS::Partition}:iam::${PnCoreAwsAccountId}:root"
            Condition:
              ArnLike:
                aws:PrincipalArn:
                  - !Sub "arn:${AWS::Partition}:iam::${PnCoreAwsAccountId}:role/pn-data-monitoring-codebuild-role"
                  - !Sub "arn:${AWS::Partition}:iam::${PnCoreAwsAccountId}:role/pn-data-monitoring-ec2-service-role"
                  - !Sub "arn:${AWS::Partition}:iam::${PnCoreAwsAccountId}:instance-profile/pn-data-monitoring-ec2-instance-profile"
                  - !Sub "arn:${AWS::Partition}:sts::${PnCoreAwsAccountId}:assumed-role/pn-data-monitoring-ec2-service-role/*"
          - Fn::If:
            - IsDatalakeAccount
            - Effect: Allow
              Action:
                - "s3:Get*"
                - "s3:List*"
              Resource:
                - !Sub "arn:aws:s3:::${DataMonitoringBucket}"
                - !Sub "arn:aws:s3:::${DataMonitoringBucket}/*"
              Principal:
                AWS:
                  - !Sub "arn:${AWS::Partition}:iam::${DataLakeAccountId}:root"
              Condition:
                ArnLike:
                  aws:PrincipalArn:
                    - !Sub "arn:${AWS::Partition}:iam::${DataLakeAccountId}:role/${DataLakeRoleName}"
            - !Ref AWS::NoValue

  DataMonitoringBucketPolicyCore:
    Condition: IsDatalakeAccountInCore
    Type: AWS::S3::BucketPolicy
    Properties:
      Bucket: !Ref DataMonitoringBucket
      PolicyDocument:
        Version: "2012-10-17"
        Statement:
          - Effect: Allow
            Action:
              - "s3:Get*"
              - "s3:List*"
            Resource:
              - !Sub "arn:aws:s3:::${DataMonitoringBucket}"
              - !Sub "arn:aws:s3:::${DataMonitoringBucket}/*"
            Principal:
              AWS:
                - !Sub "arn:${AWS::Partition}:iam::${DataLakeAccountId}:root"
            Condition:
              ArnLike:
                aws:PrincipalArn:
                  - !Sub "arn:${AWS::Partition}:iam::${DataLakeAccountId}:role/${DataLakeRoleName}"
  
  DataMonitoringCodebuildProject:
    Type: 'AWS::CodeBuild::Project'
    Properties:
      Name: pn-data-monitoring-codebuild
      ServiceRole: !GetAtt DataMonitoringCodeBuildServiceRole.Arn
      ConcurrentBuildLimit: 1
      TimeoutInMinutes: 360
      Source: 
        Type: NO_SOURCE
        BuildSpec: |
          version: 0.2
          phases:
            pre_build:
              commands:
                - ROOT_FOLDER=$(pwd) && echo ${ROOT_FOLDER}
                - git clone https://github.com/pagopa/pn-troubleshooting.git
                - git clone https://github.com/pagopa/pn-prototypes.git
                - ( cd ${ROOT_FOLDER}/pn-prototypes && git checkout $PROTOTYPE_VERSION )
                - ( cd ${ROOT_FOLDER}/pn-troubleshooting && git checkout $SCRIPTS_VERSION )
            build:
              commands:
                - ROOT_FOLDER=$(pwd) && echo ${ROOT_FOLDER}
                - |
                  cd pn-troubleshooting/bi_or_not_bi__ec_metadata
                  ./cicd_runner.sh \
                      --account-type $ACCOUNT_TYPE \
                      --env-type $ENV_TYPE \
                      --export-bucket-name $EXPORT_BUCKET_NAME \
                      --logs-bucket-name $LOGS_BUCKET_NAME \
                      --resource-root $ROOT_FOLDER/pn-prototypes \
                      --core-bucket-name $CORE_BUCKET \
                      --confinfo-bucket-name $CONFINFO_BUCKET \
                      --timestamp-utc "$DATE_EXECUTION"
      Artifacts:
        Type: NO_ARTIFACTS
      Environment:
        ComputeType: BUILD_GENERAL1_XLARGE
        Type: LINUX_CONTAINER
        Image: "aws/codebuild/standard:7.0-24.10.02"
        EnvironmentVariables:
          - Name: REGION
            Type: PLAINTEXT
            Value: !Ref AWS::Region
          - Name: EXPORT_BUCKET_NAME
            Type: PLAINTEXT
            Value: !Ref DataMonitoringBucket
          - Name: LOGS_BUCKET_NAME
            Type: PLAINTEXT
            Value: !Ref LogsBucketName
          - Name: ACCOUNT_TYPE
            Type: PLAINTEXT
            Value: !If [IsCoreAccount, "core", "confinfo"]
          - Name: ENV_TYPE
            Type: PLAINTEXT
            Value: !Ref EnvironmentType
          - Name: SCRIPTS_VERSION
            Type: PLAINTEXT
            Value: !Ref DataMonitoringScriptVersion
          - Name: PROTOTYPE_VERSION
            Type: PLAINTEXT
            Value: !Ref DataMonitoringPrototypeVersion
          - Name: CORE_BUCKET
            Type: PLAINTEXT
            Value: !If [IsCoreAccount, !Ref DataMonitoringBucket, !Sub "pn-datamonitoring-${AWS::Region}-${PnCoreAwsAccountId}"]
          - Name: CONFINFO_BUCKET
            Type: PLAINTEXT
            Value: !If [IsCoreAccount, !Ref ConfinfoDynamoDbExportBucketName, !Ref DataMonitoringBucket]
          - Name: DATE_EXECUTION
            Type: PLAINTEXT
            Value: ""

  DataMonitoringCodeBuildServiceRole:
    Type: AWS::IAM::Role
    Properties:
      RoleName: pn-data-monitoring-codebuild-role
      AssumeRolePolicyDocument:
        Version: "2012-10-17"
        Statement:
          - Effect: Allow
            Principal:
              Service:
                - "codebuild.amazonaws.com"
            Action:
              - "sts:AssumeRole"
          - Effect: Allow
            Principal:
              AWS:
                - !Sub "arn:${AWS::Partition}:iam::${AWS::AccountId}:root"
            Condition:
              ArnEquals:
                aws:PrincipalArn: !Sub arn:${AWS::Partition}:iam::${AWS::AccountId}:role/pn-data-monitoring-codebuild-role
            Action:
              - "sts:AssumeRole" 

  EC2DataMonitoringInstanceProfile:
    Type: AWS::IAM::InstanceProfile
    Condition: IsCoreAccount
    Properties:
      InstanceProfileName: pn-data-monitoring-ec2-instance-profile
      Path: "/"
      Roles:
        - !Ref EC2DataMonitoringServiceRole
  
  EC2DataMonitoringServiceRole:
    Type: AWS::IAM::Role
    Condition: IsCoreAccount
    Properties:
      RoleName: pn-data-monitoring-ec2-service-role
      AssumeRolePolicyDocument:
        Version: "2012-10-17"
        Statement:
          - Effect: Allow
            Principal:
              Service:
                - "ec2.amazonaws.com"
            Action:
              - "sts:AssumeRole"
      ManagedPolicyArns:
        - arn:aws:iam::aws:policy/AmazonSSMManagedInstanceCore

  DataMonitoringEC2ManagedPolicy:
    Type: AWS::IAM::ManagedPolicy
    Condition: IsCoreAccount
    Properties:
      ManagedPolicyName: pn-data-monitoring-ec2-managed-policy
      Roles:
        - !Ref EC2DataMonitoringServiceRole
      PolicyDocument:
        Version: "2012-10-17"
        Statement:
          # lettura su tutto il bucket dei log e parquet
          - Effect: Allow
            Action:
              - "s3:Get*"
              - "s3:List*"
            Resource: 
              - !Sub "arn:aws:s3:::${LogsBucketName}"
              - !Sub "arn:aws:s3:::${LogsBucketName}/*"
              - !Sub "arn:aws:s3:::${DataMonitoringBucket}"
              - !Sub "arn:aws:s3:::${DataMonitoringBucket}/*"
          # Accesso in scrittura al bucket dump dell'account corrente nella cartella parquet
          - Effect: Allow
            Action:
              - "s3:PutObject"
              - "s3:DeleteObject"
            Resource: 
              - !Sub "arn:aws:s3:::${DataMonitoringBucket}/${ParquetBucketPath}/*"
              - !Sub "arn:aws:s3:::${DataMonitoringBucket}/${ReportsBucketPath}/*"
          # Accessi in lettura al bucket dump dell'account confinfo nella cartella parquet
          - Fn::If:
            - IsCoreAccount
            - Effect: Allow
              Action:
                - "s3:Get*"
                - "s3:List*"
              Resource: 
              - !Sub "arn:aws:s3:::${ConfinfoDynamoDbExportBucketName}"
              - !Sub "arn:aws:s3:::${ConfinfoDynamoDbExportBucketName}/${ParquetBucketPath}/*"
            - !Ref AWS::NoValue
          # Accesso in lettura al bucket di confinfo per protocollo S3A
          - Fn::If:
            - IsCoreAccount
            - Effect: Allow
              Action:
                - "s3:ListBucket"
              Resource:
                - !Sub "arn:aws:s3:::${ConfinfoDynamoDbExportBucketName}"
            - !Ref AWS::NoValue
          # Accessi in lettura ai log di pn-delivery
          - Fn::If:
            - IsCoreAccount
            - Effect: Allow
              Action:
                - "logs:StartQuery"
                - "logs:StopQuery"
                - "logs:GetQueryResults"
              Resource: 
              - !Sub "arn:aws:logs:${AWS::Region}:${AWS::AccountId}:log-group:/aws/ecs/pn-delivery:*"
            - !Ref AWS::NoValue
          # Allow the use of encryption key
          - Effect: Allow
            Action:
              - kms:Encrypt
              - kms:Decrypt
              - kms:ReEncrypt*
              - kms:GenerateDataKey*
              - kms:DescribeKey
            Resource: 
              - !Sub "${LogsBucketKmsKeyArn}"

  DataMonitoringCodebuildManagedPolicy:
    Type: AWS::IAM::ManagedPolicy
    Properties:
      ManagedPolicyName: pn-data-monitoring-codebuild-managed-policy
      Roles:
        - !Ref DataMonitoringCodeBuildServiceRole
      PolicyDocument:
        Version: "2012-10-17"
        Statement:
          - Effect: Allow
            Action:
              - logs:CreateLogGroup
              - logs:CreateLogStream
              - logs:PutLogEvents
            Resource: !Sub arn:aws:logs:${AWS::Region}:${AWS::AccountId}:log-group:*
          # lettura su tutto il bucket dei log e parquet
          - Effect: Allow
            Action:
              - "s3:Get*"
              - "s3:List*"
            Resource: 
              - !Sub "arn:aws:s3:::${LogsBucketName}"
              - !Sub "arn:aws:s3:::${LogsBucketName}/*"
              - !Sub "arn:aws:s3:::${DataMonitoringBucket}"
              - !Sub "arn:aws:s3:::${DataMonitoringBucket}/*"
          # Accesso in scrittura al bucket dump dell'account corrente nella cartella parquet
          - Effect: Allow
            Action:
              - "s3:PutObject"
              - "s3:DeleteObject"
            Resource: 
              - !Sub "arn:aws:s3:::${DataMonitoringBucket}/${ParquetBucketPath}/*"
              - !Sub "arn:aws:s3:::${DataMonitoringBucket}/${ReportsBucketPath}/*"
          # Accessi in lettura al bucket dump dell'account confinfo nella cartella parquet
          - Fn::If:
            - IsCoreAccount
            - Effect: Allow
              Action:
                - "s3:Get*"
                - "s3:List*"
              Resource: 
              - !Sub "arn:aws:s3:::${ConfinfoDynamoDbExportBucketName}/${ParquetBucketPath}/*"       
            - !Ref AWS::NoValue
          # Accesso in lettura al bucket di confinfo per protocollo S3A
          - Fn::If:
            - IsCoreAccount
            - Effect: Allow
              Action:
                - "s3:ListBucket"
              Resource:
                - !Sub "arn:aws:s3:::${ConfinfoDynamoDbExportBucketName}"
            - !Ref AWS::NoValue
          # Accessi in lettura ai log di pn-delivery
          - Fn::If:
            - IsCoreAccount
            - Effect: Allow
              Action:
                - "logs:StartQuery"
                - "logs:StopQuery"
                - "logs:GetQueryResults"
              Resource: 
              - !Sub "arn:aws:logs:${AWS::Region}:${AWS::AccountId}:log-group:/aws/ecs/pn-delivery:*"
            - !Ref AWS::NoValue
          # Allow the use of encryption key
          - Effect: Allow
            Action:
              - kms:Encrypt
              - kms:Decrypt
              - kms:ReEncrypt*
              - kms:GenerateDataKey*
              - kms:DescribeKey
            Resource: 
              - !Sub "${LogsBucketKmsKeyArn}"

  DataMonitoringScheduleRole:
    Condition: HasCronExpression
    Type: AWS::IAM::Role
    Properties:
      AssumeRolePolicyDocument:
        Statement:
          - Action: sts:AssumeRole
            Effect: Allow
            Principal:
              Service: events.amazonaws.com
        Version: "2012-10-17"
      Policies:
        - PolicyName: runCodeBuild
          PolicyDocument:
            Statement:
              - Sid: startProjectRun
                Action:
                  - "codebuild:*"
                Effect: Allow
                Resource: 
                  - !GetAtt DataMonitoringCodebuildProject.Arn

  IndexScheduledRule:
    Type: AWS::Events::Rule
    Condition: HasCronExpression
    Properties:
      Description: "pn-data-monitoring-codebuild-scheduled-rule"
      # every day at 9 am
      ScheduleExpression: !Ref DataMonitoringIndexCronExpression 
      State: "ENABLED"
      RoleArn: !GetAtt "DataMonitoringScheduleRole.Arn"
      Targets: 
        - Id: "DataMonitoringIndex"
          RoleArn: !GetAtt "DataMonitoringScheduleRole.Arn"
          # Input:
          #   !Sub |
          #     {
          #       "environmentVariablesOverride": {
          #         "cmd": ${Cmd}
          #       }
          #     }
          Arn: 
            Fn::GetAtt: 
              - "DataMonitoringCodebuildProject"
              - "Arn"
        
  DynamoDbExportFunction:
    Type: AWS::Lambda::Function
    Condition: HasDynamoDbExportTableNames
    Properties:
      Runtime: python3.12
      Handler: index.lambda_handler
      FunctionName: Lambda-DailyExport-DynamoDbTable
      Code:
        ZipFile: |
          import boto3
          import os
          import logging
          from datetime import datetime
          from datetime import timedelta
          
          def lambda_handler(event, context):
              dynamodb = boto3.client('dynamodb')
              dynamo_table_names = os.environ['DynamoDbExportTableNames'].split(',')
              s3_bucket = os.environ['S3Bucket']
              prefix = os.environ['Prefix']
              region = os.environ['Region']
              accountid = os.environ['AccountID']
              current_date = datetime.now().strftime('%Y%m%d')
              yesterday_date= (datetime.strptime(current_date, '%Y%m%d') - timedelta(days=1)).strftime('%Y%m%d')

              for dynamo_table_name in dynamo_table_names:
                  dynamo_table_arn = f"arn:aws:dynamodb:{region}:{accountid}:table/{dynamo_table_name}"
                  s3_full_prefix = dynamo_table_name + "/" + prefix + "/" + yesterday_date
                  now = datetime.now()
                  to_time = now.replace(hour=0, minute=0, second=0, microsecond=0)
                  from_time = to_time - timedelta(days=1)
                  try:
                      dynamodb.export_table_to_point_in_time(
                                  TableArn=dynamo_table_arn,
                                  S3Bucket=s3_bucket,
                                  S3Prefix=s3_full_prefix,
                                  ExportFormat='DYNAMODB_JSON',
                                  ExportType='INCREMENTAL_EXPORT',
                                  IncrementalExportSpecification={
                                      'ExportFromTime': from_time,
                                      'ExportToTime': to_time,
                                      'ExportViewType': 'NEW_IMAGE'
                                  }
                              )
                      print(f"Tabella '{dynamo_table_name}' export start.")
                  except Exception as e:
                      print(f"Error during l'export of table '{dynamo_table_name}': {e}")

      Environment:
        Variables:
          DynamoDbExportTableNames:
            Ref: DynamoDbExportTableNames
          S3Bucket:
            Ref: DataMonitoringBucket
          Prefix:
            Ref: DynamoDbExportPrefix
          Region: !Ref AWS::Region
          AccountID: !Ref AWS::AccountId


      Role:
        Fn::GetAtt:
          - ExportRole
          - Arn

  ExportRole:
    Type: AWS::IAM::Role
    Condition: HasDynamoDbExportTableNames
    Properties:
      AssumeRolePolicyDocument:
        Version: "2012-10-17"
        Statement:
          - Effect: Allow
            Principal:
              Service: lambda.amazonaws.com
            Action: sts:AssumeRole
      Policies:
        - PolicyName: ExportPolicy
          PolicyDocument:
            Version: "2012-10-17"
            Statement:
              - Effect: Allow
                Action:
                  - dynamodb:Scan
                  - dynamodb:ExportTableToPointInTime
                Resource: arn:aws:dynamodb:*:*:*
              - Effect: Allow
                Action:
                  - s3:PutObject
                Resource:
                  - !Sub arn:aws:s3:::${DataMonitoringBucket}/*
              - Effect: Allow
                Action:
                  - "logs:CreateLogStream"
                  - "logs:PutLogEvents"
                Resource: arn:aws:logs:*:*:*
              - Effect: Allow
                Action:
                  - "kms:Decrypt"
                Resource: "*"

  Schedule:
    Type: AWS::Events::Rule
    Condition: HasDynamoDbExportTableNames
    Properties:
      ScheduleExpression: cron(0 5 * * ? *)
      State: ENABLED
      Targets:
        - Arn: !GetAtt DynamoDbExportFunction.Arn
          Id: DynamoDbExportFunction

  PermissionForEventsToInvokeLambda:
    Type: AWS::Lambda::Permission
    Condition: HasDynamoDbExportTableNames
    Properties:
      Action: lambda:InvokeFunction
      FunctionName: !Ref DynamoDbExportFunction
      Principal: events.amazonaws.com
      SourceArn: !GetAtt Schedule.Arn

  ExportFunctionLogroup:
    Type: AWS::Logs::LogGroup
    Condition: HasDynamoDbExportTableNames
    DeletionPolicy: Delete
    UpdateReplacePolicy : Delete
    Properties:
      LogGroupName: !Sub "/aws/lambda/${DynamoDbExportFunction}"
      RetentionInDays: 3
  

  # Send codebuild events to Frankfurt; Needed by celonis :(
  SendCodeBuildEventsToFrankfurt: 
    Type: AWS::Events::Rule
    Properties: 
      Description: "Routes datamonitoring ends to eu-central-1"
      State: "ENABLED"
      EventPattern:
        source:  [ "aws.codebuild" ]
        detail-type: [ "CodeBuild Build State Change" ]
        detail: 
          project-name: [ "pn-data-monitoring-codebuild" ]
      Targets: 
        - Arn: !Sub "arn:${AWS::Partition}:events:eu-central-1:${AWS::AccountId}:event-bus/default"
          Id: "CrossRegionDestinationBus"
          RoleArn: !GetAtt SendCodeBuildEventsToFrankfurtRole.Arn
  
  SendCodeBuildEventsToFrankfurtRole:
    Type: AWS::IAM::Role
    Properties:
      AssumeRolePolicyDocument:
        Version: 2012-10-17
        Statement:
        - Effect: Allow
          Principal:
            Service: events.amazonaws.com
          Action: sts:AssumeRole
      Path: /
      Policies:
      - PolicyName: PutEventsDestinationBus
        PolicyDocument:
          Version: 2012-10-17
          Statement:
          - Effect: Allow
            Action:
            - events:PutEvents
            Resource:
            - !Sub "arn:${AWS::Partition}:events:eu-central-1:${AWS::AccountId}:event-bus/default"

  PaperRequestErrorDumpFuction:
    Condition: IsCoreAccount
    Type: AWS::Lambda::Function
    Properties:
      Runtime: python3.12
      Timeout: 600
      MemorySize: 384
      Handler: index.lambda_handler
      FunctionName: Lambda-PaperRequestErrorDump
      Code:
        ZipFile: |
          import os
          import boto3
          import csv
          import io
          from datetime import datetime
          from email.message import EmailMessage
          from botocore.config import Config

          dynamodb = boto3.resource('dynamodb')
          s3 = boto3.client(
              's3',
              region_name=os.environ['Region'],
              config=Config(s3={'addressing_style': 'virtual'})
          )
          sns = boto3.client('sns')
          sts = boto3.client('sts')

          def lambda_handler(event, context):
              dynamo_table_name = os.environ['DynamoDbTableLambdaDump']
              s3_bucket = os.environ['S3Bucket']
              prefix = os.environ['Prefix']
              region = os.environ['Region']
              accountid = os.environ['AccountID']
              category_filter = 'RENDICONTAZIONE_SCARTATA'
              delete_items = os.environ.get('DeleteItems', 'false').lower() == 'true'
              sns_topic_arn = os.environ['SnsTopicArn']
              presignedurltime = os.environ['PresignedUrlTime']
              timestamp = datetime.now().strftime('%Y%m%d_%H%M')
              timestampSubject = datetime.now().strftime('%Y-%m-%d')
              s3_key = f'{prefix}/rendicontazione_scartata_{timestamp}.csv'

              table = dynamodb.Table(dynamo_table_name)
              all_items = []
              exclusive_start_key = None

              while True:
                  scan_params = {
                      'FilterExpression': 'category = :val',
                      'ExpressionAttributeValues': {':val': category_filter}
                  }
                  if exclusive_start_key:
                      scan_params['ExclusiveStartKey'] = exclusive_start_key

                  response = table.scan(**scan_params)
                  all_items.extend(response.get('Items', []))
                  exclusive_start_key = response.get('LastEvaluatedKey')
                  if not exclusive_start_key:
                      break

              csv_buffer = io.StringIO()
              if all_items:
                  headers = all_items[0].keys()
                  writer = csv.DictWriter(csv_buffer, fieldnames=headers)
                  writer.writeheader()
                  for item in all_items:
                      writer.writerow(item)

              s3.put_object(
                  Bucket=s3_bucket,
                  Key=s3_key,
                  Body=csv_buffer.getvalue()
              )

              presigned_url = s3.generate_presigned_url(
                  ClientMethod='get_object',
                  Params={
                      'Bucket': s3_bucket,
                      'Key': s3_key,
                      'ResponseContentDisposition': 'inline'
                  },
                  ExpiresIn=presignedurltime
              )

              sns.publish(
                  TopicArn=sns_topic_arn,
                  Subject=f'CSV Rendicontazione Scartata {timestampSubject}',
                  Message=f"In allegato il link per scaricare il file CSV:\n\n{presigned_url}"
              )

              if delete_items:
                  for item in all_items:
                      request_id = item.get('requestId')
                      created = item.get('created')
                      if request_id and created:
                          try:
                              response = table.delete_item(
                                  Key={
                                      'requestId': request_id,
                                      'created': created
                                  }
                              )
                              print(f"Deleted item with requestId: {request_id} and created: {created}")
                          except Exception as e:
                              print(f'Error During cancellation of item {request_id}: {str(e)}')    

              return {
                  'statusCode': 200,
                  'body': f'CSV with {len(all_items)} records uploaded on s3://{s3_bucket}/{s3_key} and link send by Email.'
              }



      Environment:
        Variables:
          DynamoDbTableLambdaDump: pn-PaperRequestError
          S3Bucket: !Ref DataMonitoringBucket
          Prefix: Lambda-PaperRequestErrorDump
          DeleteItems: !Ref PaperRequestErrorDumpFuctionDelete
          SnsTopicArn: !Ref EMailSnsTopic
          Region: !Ref AWS::Region
          AccountID: !Ref AWS::AccountId
          PresignedUrlTime: !Ref PresignedUrlTimeOfexpiration

      Role:
        Fn::GetAtt:
          - PaperRequestErrorDumpFuctionRole
          - Arn

  PaperRequestErrorDumpFuctionAlarms:
    Type: AWS::CloudFormation::Stack
    Properties:
      TemplateURL: !Sub "${TemplateBucketBaseUrl}/fragments/lambda-alarms.yaml"
      Parameters:
        FunctionName: !Ref PaperRequestErrorDumpFuction
        AlarmSNSTopicArn: !Ref AlarmSNSTopicArn
        FilterPattern: "ERROR"

  PaperRequestErrorDumpFuctionRole:
    Condition: IsCoreAccount
    Type: AWS::IAM::Role
    Properties:
      AssumeRolePolicyDocument:
        Version: "2012-10-17"
        Statement:
          - Effect: Allow
            Principal:
              Service: lambda.amazonaws.com
            Action: sts:AssumeRole
      Policies:
        - PolicyName: ExportPolicy
          PolicyDocument:
            Version: "2012-10-17"
            Statement:
              - Effect: Allow
                Action:
                  - dynamodb:Scan
                  - dynamodb:DeleteItem
                Resource: !Sub arn:aws:dynamodb:${AWS::Region}:${AWS::AccountId}:table/pn-PaperRequestError
              - Effect: Allow
                Action:
                  - s3:PutObject
                  - s3:GetObject
                Resource:
                  - !Sub arn:aws:s3:::${DataMonitoringBucket}/Lambda-PaperRequestErrorDump/*
              - Effect: Allow
                Action:
                  - logs:CreateLogStream
                  - logs:PutLogEvents
                Resource: arn:aws:logs:*:*:*
              - Effect: Allow
                Action:
                  - kms:Decrypt
                Resource: "*"
              - Effect: Allow
                Action:
                  - sns:Publish
                Resource: !Ref EMailSnsTopic

  EMailSnsTopic:
    Condition: IsCoreAccount
    Type: AWS::SNS::Topic
    Properties:
      TopicName: pn-SnsToEmail

  EMailSnsTopicSubscription:
    Condition: IsCoreAccount
    Type: AWS::SNS::Subscription
    Properties:
      Protocol: email
      Endpoint: !Ref DataMonitoringSlackEmailTo
      TopicArn: !Ref EMailSnsTopic

  LambdaSNSTopicPolicy:
    Condition: IsCoreAccount
    Type: AWS::SNS::TopicPolicy
    Properties:
      Topics:
        - !Ref EMailSnsTopic
      PolicyDocument:
        Version: "2012-10-17"
        Statement:
          - Effect: Allow
            Principal:
              Service:
              - lambda.amazonaws.com
            Action: sns:Publish
            Resource: !Ref EMailSnsTopic

  ScheduleErrorDumpFuction:
    Condition: HasCronExpressionLambdaPaperError
    Type: AWS::Events::Rule
    Properties:
      ScheduleExpression: !Ref PaperRequestErrorDumpFuctionCronExpression
      State: ENABLED
      Targets:
        - Arn: !GetAtt PaperRequestErrorDumpFuction.Arn
          Id: PaperRequestErrorDumpFuction

  PermissionForEventsToInvokeErrorDumpFuction:
    Condition: HasCronExpressionLambdaPaperError
    Type: AWS::Lambda::Permission
    Properties:
      Action: lambda:InvokeFunction
      FunctionName: !Ref PaperRequestErrorDumpFuction
      Principal: events.amazonaws.com
      SourceArn: !GetAtt ScheduleErrorDumpFuction.Arn

  ErrorDumpFuctionLogroup:
    Condition: IsCoreAccount
    Type: AWS::Logs::LogGroup
    DeletionPolicy: Delete
    UpdateReplacePolicy : Delete
    Properties:
      LogGroupName: !Sub "/aws/lambda/${PaperRequestErrorDumpFuction}"
      RetentionInDays: 3
     
Outputs:
  DataMonitoringBucketName: 
    Value: !Ref DataMonitoringBucket
    Description: Name of the bucket created for the data monitoring
